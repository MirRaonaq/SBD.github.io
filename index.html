<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="icon" href="MIR.png">
  <title>Mir Raonaq - SBD Project Blog</title>

  <!-- All CSS Plugins -->
  <link rel="stylesheet" type="text/css" href="css/plugin.css">

  <!-- Main CSS Stylesheet -->
  <link rel="stylesheet" type="text/css" href="css/style.css">

  <!-- Google Web Fonts  -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins:400,300,500,600,700">


</head>

<body>




  <div id="main">
    <div class="container">
      <div class="row">
        <div class="col-md-12 page-body">
          <div class="row">
            <div class="title">
              <h2 align="middle">SBD Without Punctuation <br> Project Blog</h2>
            </div>
            <div class="sub-title">
              <h2>Mir Raonaq</h2>
              <h4><a href="https://www.mirraonaq.com/" target="_blank">Home</a></h4>

              <h4><a href="https://www.overleaf.com/read/hkzwtmfrgdrf" target="_blank">Project</a></h4>

              <h4><a href="https://github.com/MirRaonaq/SBD" target="_blank">Data & Code</a></h4>

              <h4><a href="https://www.overleaf.com/read/zqxbptrdwqdb" target="_blank">Poster</a></h4>
            </div>

            <div class="col-md-12 blog-post">
              <div class="post-title">
                <h1>Abstract</h1>
              </div>
              <p>In this project, we will be focusing on sentence boundary detection (sbd) without punctuation marks. We will be researching current solutions from the Natural Language Processor, (NLP) splitta in order to provide us with results. Using the information gathered from conducting multiple tests, we will conclude why sbd is not accurate and form a solution to detect sentence segmentation without punctuation marks.</p>
            </div>

            <div class="col-md-12 blog-post">
              <div class="post-title">
                <h1>Syntactic Parsing</h1>
              </div>
              <div class="post-info">
                <span>November 25, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
              </div>
              <p>Parsing is the process of analyzing a string of symbols. Syntactic parsing is the task of recognizing a sentence and assigning a syntactic structure to it. However, structural ambiguity occurs when the grammar can assign more than one parse to a sentence. For example, if a sentence such as “One morning I shot an elephant in my pajamas. How he got into my pajamas I don’t know.” Once parsed, these collection of words would be difficult to analyze due to its ambiguous nature. Simple sentences such as “Good morning, how are you?” are easy for NPL to process because there is no ambiguity and has a straight forward structure. [<a href="https://web.stanford.edu/~jurafsky/slp3/11.pdf" target="_blank">https://web.stanford.edu</a>]</p>
            </div>

            <div class="col-md-12 blog-post">
              <div class="post-title">
                <h1>Part of Speech Tagging (POS)</h1>
              </div>
              <div class="post-info">
                <span>November 21, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
              </div>
              <p>A big reason why NLP today has been successful is because of Part of Speech (POS) tagging. It helps programs capture the structure of the sentences and sometimes provides appropriate meanings. The part of speech is split into eight parts, which are nouns, pronouns, adjectives, verbs, adverbs, prepositions, conjunctions and interjections. Based on the current, previous, and next words, the software decides the which part of speech to tag the word with. The most popular tag set is Penn Treebank tagset: </p>
              <img src="Penn.png" alt="Penn">
            </div>

              <div class="col-md-12 blog-post">
                <div class="post-title">
                  <h1>What Started NLP?</h1>
                </div>
                <div class="post-info">
                  <span>November 18, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
                </div>
                <p>The Georgetown experiment in 1954 introduced a fully automated machine that translated more than sixty Russian sentences to English. Researchers began to believe that machine translation would be a solved problem after five years. However, took on a much slower pace, as researchers failed to reach expectations. It was not until 1980 when progression in NLP had picked up again. The introduction of machine learning algorithms for language processing has sparked the interest of researchers. Avram Chomsky (famous for the contributions in linguistics) was a major contributor to the advancement in NLP.</p>
              </div>

              <div class="col-md-12 blog-post">
                <div class="post-title">
                  <h1>How Google uses NLP today!</h1>
                </div>
                <div class="post-info">
                  <span>November 14, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
                </div>
                <p>A portion of Googles current success can be in large part to NLP. Google Now uses NLP for syntax, part of speech tagging and parsing in 60+ languages. Semantics for Google Search recognizes entities in text to figure out the best search results for the user. Knowledge extraction to learn relations between entities, recognize events, match entities between queries and documents. All of this cannot be done in a couple of years. To build a company like Google with the software and technology that have developed takes thousands of workers with more than 5 years of craft.
                </p>
                <img src="blogpic.png" alt="blog picture">
              </div>

              <div class="col-md-12 blog-post">
                <div class="post-title">
                  <h1>My thoughts on SBD for NLP</h1>
                </div>
                <div class="post-info">
                  <span>November 11, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
                </div>
                <p>After completing half of my project on sbd without punctuation. I have come to the realization that it will not be possible to have one system that works for every language. No matter how advanced AI develops, there is no possible way to detect sentence segmentation error free. This is in large part to humans not perfecting punctuation in languages. Although, it might be easy for a human to read and decide where a sentence ends and begins. It’s not for a NLP because of the multitude of exceptions and non-exceptions.
                </p>
              </div>

              <div class="col-md-12 blog-post">
                <div class="post-title">
                  <h1>Natural Language Processing (NLP) for Arabic</h1>
                </div>
                <div class="post-info">
                  <span>November 8, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
                </div>
                <p>Nearly 500 million people worldwide speak Arabic. The language of Arabic holds deep cultural, religious, and political significance. It is the fifth most spoken language in the world, the official language in 22 countries and is one of the six official United Nation languages. However, Arabic has received comparatively little attention in modern computational linguistics. It can be due to a number of reasons such as its complex tokenization. I believe once machine translation progresses, Semitic languages like Arabic will get more attention.
                </p>
              </div>

              <div class="col-md-12 blog-post">
                <div class="post-title">
                  <h1>Natural Language Processing (NLP)</h1>
                </div>
                <div class="post-info">
                  <span>November 5, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
                </div>
                <p>NLP is a branch of Artificial Intelligence (AI). It’s ability of a computer program to understand the human spoken language. Humans speak about 2,000 languages, each language also having their own set of rules. </p>
                <p><strong>Why is NLP Important? </p>
                  <p>In short, NLP helps with speech or text analytics. Some examples are text mining, machine translation, and automated question answering. It open doors to new possibilities of AI development, which can lead to efficient programs. </p>
                  <p><strong>Some NLP Tools:</p>
                    <p>These programs include various languages</p>
                    <p><a href="https://github.com/lukeorland/splitta" target="_blank">splitta</a>(used for this project)</p>
                    <p><a href="https://stanfordnlp.github.io/CoreNLP/" target="_blank">ssplit in CoreNLP</a></p>
                    <p><a href="http://gmb.let.rug.nl/elephant/about.php" target="_blank">elephant</a></p>
                  </div>

                  <div class="col-md-12 blog-post">
                    <div class="post-title">
                      <h1>SBD for the Arabic language</h1>
                    </div>
                    <div class="post-info">
                      <span>November 2, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
                    </div>
                    <p>Sbd for Arabic uses the following set of general rules:</p>
                    <p>• A period ending a sentence</p>
                    <p>• Based on the last word of the current sentence and the first word of the next sentence</p>
                    <p> There is no natural processing language tool for Arabic that can give us data for the error rates. I assume the error rate is higher than English because of the usage of punctuation in Arabic is peculiar. Also more research has been done for the English language.</p>
                  </div>
                  <!-- Blog Post Start -->
                  <div class="col-md-12 blog-post">
                    <div class="post-title">
                      <h1>SBD for the English language</h1>
                    </div>
                    <div class="post-info">
                      <span>October 31, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
                    </div>
                    <p>Sbd for English uses the following set of general rules:</p>
                    <p>• A period ending a sentence</p>
                    <p>• The following token after a period is capitalized</p>
                    <p>• Multiple abbreviations not ending a sentence</p>
                    <p>These three strategies work 95% of the time. After including more rules like elephant does, sbd works 99.73%. That is very close to perfect, but not quite there yet. How can we make the error rate 0? Well the problem comes from ambiguous periods that stem from abbreviations, ellipses, and decimal points. There has been rules to combat this but never perfect.
                    </p>

                  </div>

                  <div class="col-md-12 blog-post">
                    <div class="post-title">
                      <h1>Some Problem with SBD</h1>
                    </div>
                    <div class="post-info">
                      <span>October 27, 2018 / by <a href="https://www.mirraonaq.com/" target="_blank">Mir Raonaq</a></span>
                    </div>
                    <p>1. One major flaw is detecting the end of a sentence without punctuation, which is what my project research is about.
                    </p>
                    <p> 2. Due to low error rates, sbd is a problem some consider to be solved. However, these small errors still lead to misguided data and analytics.
                    </p>
                    <p> 3. Most tokenizers are rule-based on each specific language. Such as English has its own set of rules that cannot be used for Italian. This makes it difficult to adapt to new languages. I believe if natural language processing tools continue with rules based segmentation then it will always be hard to adapt to new languages.
                    </p>
                  </div>

<div class="col-md-12 text-center">
  <a href="javascript:void(0)" id="load-more-post" class="load-more-button">Load</a>
  <div id="post-end-message"></div>
</div>

</div>

</div>



<div class="col-md-8 col-md-offset-2">

</div>

</div>

<div class="col-md-12 page-body margin-top-50 footer">
  <footer>
    <ul class="menu-link">
      <li><a href="https://www.mirraonaq.com/" target="_blank" >Home</a></li>
      <li><a href="https://www.linkedin.com/in/mirraonaq/" target="_blank" >LinkedIn</a></li>
      <li><a href="https://github.com/MirRaonaq" target="_blank">GitHub</a></li>
    </ul>



  </footer>
</div>
<!-- Footer End -->


</div>
<!-- Blog Post (Right Sidebar) End -->

</div>
</div>
</div>
<!-- Back to Top Start -->
<a href="#" class="scroll-to-top"><i class="fa fa-long-arrow-up"></i></a>
<!-- Back to Top End -->


<!-- All Javascript Plugins  -->
<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/plugin.js"></script>

<!-- Main Javascript File  -->
<script type="text/javascript" src="js/scripts.js"></script>


</body>
</html>
